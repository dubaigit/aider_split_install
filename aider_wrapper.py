import os
import sys
import argparse
import subprocess
import tempfile
import select
import re
import time
import queue
import json
import base64
import asyncio
import threading
import tkinter as tk
from tkinter import ttk, scrolledtext, filedialog
import pyaudio

# Optional imports with fallbacks
try:
    import sounddevice as sd
except ImportError:
    print("Warning: sounddevice module not found. Voice functionality will be disabled.")
    sd = None

try:
    import numpy as np
except ImportError:
    print("Warning: numpy module not found. Voice functionality will be disabled.")
    np = None

try:
    import websockets
except ImportError:
    print("Warning: websockets module not found. Voice functionality will be disabled.")
    websockets = None

try:
    from openai import OpenAI
except ImportError:
    print("Warning: openai module not found. Voice functionality will be disabled.")
    OpenAI = None

try:
    import pyperclip
except ImportError:
    print("Warning: pyperclip module not found. Clipboard functionality will be disabled.")
    pyperclip = None

try:
    from tqdm import tqdm
except ImportError:
    print("Warning: tqdm module not found. Progress bar functionality will be disabled.")
    tqdm = None

try:
    import git
except ImportError:
    print("Warning: git module not found. Git functionality will be disabled.")
    git = None

# Audio settings
CHUNK_SIZE = 1024  # Smaller chunks for more responsive audio
SAMPLE_RATE = 24000
CHANNELS = 1
FORMAT = pyaudio.paInt16
REENGAGE_DELAY_MS = 500
OPENAI_WEBSOCKET_URL = "wss://api.openai.com/v1/audio/realtime"

class AiderVoiceGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Aider Voice Assistant")
        self.root.geometry("1200x800")
        
        # Initialize all attributes
        self.response_active = False
        self.last_transcript_id = None
        self.last_audio_time = time.time()
        self.recording = False
        self.auto_mode = False
        self.audio_queue = queue.Queue()
        self.ws = None
        self.running = True
        self.client = OpenAI()
        self.aider_process = None
        self.temp_files = []
        self.fixing_issues = False
        self.mic_active = False
        self.mic_on_at = 0
        self._stop_event = threading.Event()
        self.log_frequency = 50
        self.log_counter = 0
        self.chunk_buffer = []
        self.chunk_buffer_size = 5
        self.audio_thread = None
        
        # Track interface state and content
        self.interface_state = {
            'files': {},  # Store file contents
            'issues': [],  # Store detected issues
            'aider_output': [],  # Store Aider responses
            'clipboard_history': [],  # Track clipboard content
            'last_analysis': None,  # Store last analysis results
        }
        
        # Create main frame with padding
        self.main_frame = ttk.Frame(root, padding="10")
        self.main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Create left panel for controls and input
        self.left_panel = ttk.Frame(self.main_frame)
        self.left_panel.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5)
        
        # Control buttons frame
        self.control_frame = ttk.LabelFrame(self.left_panel, text="Controls", padding="5")
        self.control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=5)
        
        # Remove Voice Control button (Voice starts automatically)
        # self.voice_button = ttk.Button(
        #     self.control_frame,
        #     text="üé§ Start Voice Control",
        #     command=self.toggle_voice_control
        # )
        # self.voice_button.grid(row=0, column=0, pady=5, padx=5, sticky='ew')
        
        # Status label
        self.status_label = ttk.Label(self.control_frame, text="Initializing Voice Control...")
        self.status_label.grid(row=0, column=1, pady=5, padx=5)
        
        # Action buttons
        self.add_files_button = ttk.Button(
            self.control_frame,
            text="üìÅ Add Files",
            command=self.browse_files
        )
        self.add_files_button.grid(row=1, column=0, pady=5, padx=5, sticky='ew')
        
        self.check_issues_button = ttk.Button(
            self.control_frame,
            text="üîç Check Issues",
            command=self.check_all_issues
        )
        self.check_issues_button.grid(row=1, column=1, pady=5, padx=5, sticky='ew')
        
        # Listbox to display added files
        self.files_frame = ttk.LabelFrame(self.left_panel, text="Added Files", padding="5")
        self.files_frame.grid(row=2, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        self.files_listbox = tk.Listbox(self.files_frame, height=10)
        self.files_listbox.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.remove_file_button = ttk.Button(
            self.files_frame,
            text="üóëÔ∏è Remove Selected",
            command=self.remove_selected_file
        )
        self.remove_file_button.grid(row=1, column=0, pady=5, padx=5, sticky='ew')
        
        # Input frame
        self.input_frame = ttk.LabelFrame(self.left_panel, text="Input/Instructions", padding="5")
        self.input_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        self.input_text = scrolledtext.ScrolledText(self.input_frame, height=10)
        self.input_text.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.clipboard_button = ttk.Button(
            self.input_frame,
            text="üìã Load Clipboard",
            command=self.use_clipboard_content
        )
        self.clipboard_button.grid(row=1, column=0, pady=5, padx=5)
        
        self.send_button = ttk.Button(
            self.input_frame,
            text="üì§ Send to Aider",
            command=self.send_input_text
        )
        self.send_button.grid(row=1, column=1, pady=5, padx=5)
        
        # Create right panel for output
        self.right_panel = ttk.Frame(self.main_frame)
        self.right_panel.grid(row=0, column=1, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5)
        
        # Transcription frame
        self.transcription_frame = ttk.LabelFrame(self.right_panel, text="Conversation", padding="5")
        self.transcription_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        self.transcription_text = scrolledtext.ScrolledText(self.transcription_frame, height=15)
        self.transcription_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Issues frame
        self.issues_frame = ttk.LabelFrame(self.right_panel, text="Issues", padding="5")
        self.issues_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        self.issues_text = scrolledtext.ScrolledText(self.issues_frame, height=15)
        self.issues_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Create log frame
        self.log_frame = ttk.LabelFrame(self.left_panel, text="Log", padding="5")
        self.log_frame.grid(row=4, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        
        # Create output text area (for logging)
        self.output_text = scrolledtext.ScrolledText(self.log_frame, height=10)
        self.output_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Configure grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        self.main_frame.columnconfigure(1, weight=2)  # Right panel takes more space
        self.main_frame.rowconfigure(0, weight=1)
        self.left_panel.columnconfigure(0, weight=1)
        self.left_panel.rowconfigure(4, weight=1)  # Log frame takes remaining space
        self.right_panel.columnconfigure(0, weight=1)
        self.right_panel.rowconfigure(0, weight=1)
        self.right_panel.rowconfigure(1, weight=1)
        self.files_frame.columnconfigure(0, weight=1)
        self.input_frame.columnconfigure(0, weight=1)
        self.input_frame.columnconfigure(1, weight=1)
        self.control_frame.columnconfigure(1, weight=1)
        
        # Initialize other attributes
        self.recording = False
        self.auto_mode = False
        self.audio_queue = queue.Queue()
        self.ws = None
        self.running = True
        self.client = OpenAI()
        self.aider_process = None
        self.temp_files = []
        self.fixing_issues = False
        
        # Initialize asyncio loop
        self.loop = asyncio.new_event_loop()
        self.thread = threading.Thread(target=self.run_async_loop, daemon=True)
        self.thread.start()
        
        # Initialize audio components
        self.p = pyaudio.PyAudio()
        self.audio_buffer = bytearray()  # Changed from bytes to bytearray
        self.mic_queue = queue.Queue()
        self.mic_on_at = 0
        self.mic_active = False
        self._stop_event = threading.Event()
        
        # Add performance settings
        self.log_frequency = 50  # Only log every 50th audio chunk
        self.log_counter = 0
        self.chunk_buffer = []  # Buffer for accumulating audio chunks
        self.chunk_buffer_size = 5  # Number of chunks to accumulate before sending
        
        # Initialize audio processing thread
        self.audio_thread = None
        
        # Automatically start voice control
        self.start_voice_control()
    
    def run_async_loop(self):
        """Run asyncio event loop in a separate thread"""
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()
    
    def toggle_voice_control(self):
        """Toggle voice control on/off"""
        if not self.recording:
            self.start_voice_control()
        else:
            self.stop_voice_control()
    
    def start_voice_control(self):
        """Start voice control"""
        if None in (sd, np, websockets, OpenAI):
            self.log_message("Error: Required modules for voice control are not available")
            return
            
        self.recording = True
        # self.voice_button.configure(text="üî¥ Stop Voice Control")
        self.status_label.configure(text="Listening...")
        
        # Start audio streams
        self.mic_stream = self.p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            stream_callback=self._mic_callback,
            frames_per_buffer=CHUNK_SIZE
        )
        self.spkr_stream = self.p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            output=True,
            stream_callback=self._spkr_callback,
            frames_per_buffer=CHUNK_SIZE
        )
        
        # Start audio processing thread
        self.audio_thread = threading.Thread(target=self._process_audio_thread, daemon=True)
        self.audio_thread.start()
        
        self.mic_stream.start_stream()
        self.spkr_stream.start_stream()
        
        # Connect to OpenAI WebSocket
        asyncio.run_coroutine_threadsafe(self.connect_websocket(), self.loop)
    
    def stop_voice_control(self):
        """Stop voice control"""
        self.recording = False
        # self.voice_button.configure(text="üé§ Start Voice Control")
        self.status_label.configure(text="Ready")
        
        # Stop audio streams
        if hasattr(self, 'mic_stream'):
            self.mic_stream.stop_stream()
            self.mic_stream.close()
        if hasattr(self, 'spkr_stream'):
            self.spkr_stream.stop_stream()
            self.spkr_stream.close()
        
        # Close WebSocket connection
        if self.ws:
            asyncio.run_coroutine_threadsafe(self.ws.close(), self.loop)
            self.ws = None
        
        # Terminate PyAudio
        self.p.terminate()
    
    def _mic_callback(self, in_data: bytes, _frame_count: int, _time_info: dict, _status: int) -> tuple[None, int]:
        """Handle microphone input callback from PyAudio.
        
        Args:
            in_data: Raw audio input data
            _frame_count: Number of frames (unused but required by PyAudio API)
            _time_info: Timing information (unused but required by PyAudio API)
            _status: Status flags (unused but required by PyAudio API)
            
        Returns:
            tuple: (None, paContinue) as required by PyAudio API
        """
        if time.time() > self.mic_on_at:
            if not self.mic_active:
                self.log_message('üéôÔ∏èüü¢ Mic active')
                self.mic_active = True
            self.mic_queue.put(in_data)
            
            # Only log occasionally to reduce GUI updates
            self.log_counter += 1
            if self.log_counter % self.log_frequency == 0:
                self.log_message('üé§ Processing audio...')
        else:
            if self.mic_active:
                self.log_message('üéôÔ∏èüî¥ Mic suppressed')
                self.mic_active = False
        return (None, pyaudio.paContinue)
    
    def _process_audio_thread(self):
        """Process audio in a separate thread"""
        while self.recording:
            try:
                # Accumulate chunks
                chunks = []
                while len(chunks) < self.chunk_buffer_size:
                    try:
                        chunk = self.mic_queue.get_nowait()
                        chunks.append(chunk)
                    except queue.Empty:
                        break
                
                if chunks and self.ws:
                    # Combine chunks and send
                    combined_chunk = b''.join(chunks)
                    asyncio.run_coroutine_threadsafe(
                        self.ws.send(json.dumps({
                            'type': 'input_audio_buffer.append',
                            'audio': base64.b64encode(combined_chunk).decode('utf-8')
                        })),
                        self.loop
                    )
            except (websockets.exceptions.ConnectionClosed, json.JSONDecodeError) as e:
                self.log_message(f"Network or data error in audio processing: {e}")
            except Exception as e:
                # Catch-all for unexpected errors that shouldn't crash the thread
                self.log_message(f"Unexpected error in audio processing thread: {e}")
            
            time.sleep(0.01)  # Short sleep to prevent tight loop
    
    def _spkr_callback(self, _in_data: bytes, frame_count: int, _time_info: dict, _status: int) -> tuple[bytes, int]:
        """Handle speaker output callback from PyAudio.
        
        Args:
            _in_data: Unused input data (required by PyAudio API)
            frame_count: Number of frames to output
            _time_info: Timing information (unused but required by PyAudio API)
            _status: Status flags (unused but required by PyAudio API)
            
        Returns:
            tuple: (audio_data, paContinue) as required by PyAudio API
        """
        bytes_needed = frame_count * 2
        current_buffer_size = len(self.audio_buffer)

        if current_buffer_size >= bytes_needed:
            audio_chunk = bytes(self.audio_buffer[:bytes_needed])
            self.audio_buffer = bytearray(self.audio_buffer[bytes_needed:])  # Convert slice to bytearray
            self.mic_on_at = time.time() + REENGAGE_DELAY_MS / 1000
        else:
            audio_chunk = bytes(self.audio_buffer) + b'\x00' * (bytes_needed - current_buffer_size)
            self.audio_buffer = bytearray()  # Reset with empty bytearray

        return (audio_chunk, pyaudio.paContinue)
    
    async def connect_websocket(self):
        """Connect to OpenAI's realtime websocket API"""
        try:
            self.ws = await websockets.connect(
                f"{OPENAI_WEBSOCKET_URL}?model=gpt-4-1106-preview",
                extra_headers={
                    "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
                    "Content-Type": "application/json",
                    "OpenAI-Beta": "realtime=v1"
                }
            )
            
            # Initialize session with correct configuration
            await self.ws.send(json.dumps({
                "type": "session.update",
                "session": {
                    "model": "gpt-4",
                    "voice": "alloy",
                    "turn_detection": {
                        "type": "server_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 200,
                        "silence_duration_ms": 300
                    },
                    "temperature": 0.8,
                    "max_response_output_tokens": 2048,
                    "instructions": """
                    You are an AI assistant that helps control the Aider code assistant through voice commands.
                    
                    When a file is added:
                    1. Acknowledge the file addition
                    2. Provide a summary of the file contents (imports, classes, functions)
                    3. Ask if the user wants to analyze for issues or make changes
                    
                    When checking for issues:
                    1. Summarize the number and types of issues found
                    2. Ask if the user wants to fix them using Aider
                    
                    Commands you understand:
                    - Run Aider with clipboard content
                    - Add files to Aider (from current directory)
                    - Check for issues and send to Aider
                    - Summarize what happened when Aider finishes
                    
                    Always confirm what action you're taking and provide clear feedback.
                    Your knowledge cutoff is 2023-10. Be helpful, witty, and friendly.
                    Talk quickly and be engaging with a lively tone.
                    """
                }
            }))
            
            self.log_message("Connected to OpenAI realtime API")
            
            # Initialize response state
            self.response_active = False
            self.last_transcript_id = None
            self.audio_buffer = bytearray()
            self.last_audio_time = time.time()
            
            # Start message handling
            asyncio.create_task(self.handle_websocket_messages())
            asyncio.create_task(self.process_audio_queue())
            
        except Exception as e:
            self.log_message(f"Failed to connect to OpenAI: {e}")
            self.stop_voice_control()
    
    async def process_audio_queue(self):
        """Process audio queue and send to OpenAI"""
        while self.recording:
            if not self.mic_queue.empty():
                mic_chunk = self.mic_queue.get()
                self.log_message(f'üé§ Processing {len(mic_chunk)} bytes of audio data.')
                
                try:
                    # Send audio data to OpenAI
                    await self.ws.send(json.dumps({
                        'type': 'input_audio_buffer.append',
                        'audio': base64.b64encode(mic_chunk).decode('utf-8')
                    }))
                except Exception as e:
                    self.log_message(f"Error sending audio data: {e}")
            
            await asyncio.sleep(0.05)
    
    async def handle_websocket_messages(self):
        """Handle incoming websocket messages"""
        accumulated_text = ""  # Accumulate text before sending voice response
        
        while self.ws and self.recording:
            try:
                message = await self.ws.recv()
                event = json.loads(message)
                
                event_type = event.get("type")
                
                if event_type == "message.chunk":
                    # Handle message chunks from the assistant
                    chunk = event.get("chunk", {})
                    text = chunk.get("content", "")
                    if text.strip():
                        self.update_transcription(text, is_assistant=True)
                        self.response_active = True
                        accumulated_text += text
                
                elif event_type == "speech.chunk":
                    # Handle audio chunks from the assistant
                    try:
                        audio_content = base64.b64decode(event.get('chunk', {}).get('audio', ''))
                        if audio_content:
                            self.audio_buffer.extend(audio_content)
                            self.log_message(f'Received {len(audio_content)} bytes of audio data')
                    except Exception as e:
                        self.log_message(f"Error processing audio response: {e}")
                
                elif event_type == "speech.done":
                    self.log_message("AI finished speaking")
                    self.response_active = False
                    # Reset mic suppression after a short delay
                    await asyncio.sleep(REENGAGE_DELAY_MS / 1000)
                    self.mic_on_at = time.time()
                    accumulated_text = ""  # Reset accumulated text
                
                elif event_type == "message.done":
                    self.response_active = False
                    status = event.get("status")
                    if status == "incomplete":
                        reason = event.get("status_details", {}).get("reason", "unknown")
                        self.log_message(f"üö´ Response incomplete: {reason}")
                    elif status == "failed":
                        error = event.get("status_details", {}).get("error", {})
                        self.log_message(f"‚ö†Ô∏è Response failed: {error.get('code', 'unknown error')}")
                    else:
                        self.log_message("Response completed")
                        # Send accumulated text for voice response if not empty
                        if accumulated_text.strip():
                            await self.send_audio_response(accumulated_text)
                        accumulated_text = ""  # Reset accumulated text
                        # Re-enable mic
                        self.mic_on_at = time.time()
                
                elif event_type == "speech.transcription":
                    # Handle user speech transcription
                    text = event.get("transcription", {}).get("text", "")
                    if text.strip():
                        self.update_transcription(text, is_assistant=False)
                        await self.process_voice_command(text)
                        await self.process_voice_command(text)
                
                elif event_type == "error":
                    error_msg = event.get('error', {}).get('message', 'Unknown error')
                    self.log_message(f"Error from OpenAI: {error_msg}")
                    if "active response" in error_msg.lower():
                        self.response_active = True
                    
            except websockets.exceptions.ConnectionClosed:
                self.log_message("WebSocket connection closed")
                # Attempt to reconnect
                try:
                    await self.connect_websocket()
                except Exception as e:
                    self.log_message(f"Failed to reconnect: {e}")
                    break
            except Exception as e:
                self.log_message(f"Error handling websocket message: {e}")
    
    async def process_voice_command(self, text):
        """Process transcribed voice commands"""
        self.log_message(f"Processing command: {text}")
        
        # Send the command to the assistant
        await self.ws.send(json.dumps({
            "type": "conversation.item.create",
            "item": {
                "type": "message",
                "role": "user",
                "content": [{
                    "type": "text",
                    "text": text
                }]
            }
        }))
        
        # Log the command processing
        self.log_message("üéØ Command sent to assistant")
    
    def run_aider_with_clipboard(self):
        """Run Aider using clipboard content"""
        if self.aider_process and self.aider_process.poll() is None:
            self.log_message("Aider is already running. Please wait for it to finish.")
            return
            
        try:
            clipboard_content = pyperclip.paste()
            if not clipboard_content.strip():
                self.log_message("Clipboard is empty. Please copy some content first.")
                return
                
            # Analyze clipboard content
            analysis = self.analyze_clipboard_content(clipboard_content)
            self.interface_state['clipboard_history'].append({
                'content': clipboard_content,
                'analysis': analysis,
                'timestamp': time.time()
            })
            
            # Log analysis insights
            self.log_message("Clipboard Content Analysis:")
            self.log_message(f"- Type: {analysis['type']}")
            self.log_message(f"- Length: {analysis['length']} characters")
            self.log_message(f"- Purpose: {analysis['purpose']}")
            
            if analysis['recommendations']:
                self.log_message("Recommendations:")
                for rec in analysis['recommendations']:
                    self.log_message(f"- {rec}")

            # Start Aider process with clipboard content
            self.aider_process = subprocess.Popen(
                ["python", "aider_wrapper.py", "-c"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            self.log_message("Started Aider with clipboard content")
            
            # Monitor process output
            self.root.after(100, self.check_aider_process)
            
        except Exception as e:
            self.log_message(f"Error running Aider with clipboard: {e}")
    
    async def add_files_to_aider(self):
        """Add files from current directory to Aider"""
        if self.aider_process and self.aider_process.poll() is None:
            self.log_message("Aider is already running. Please wait for it to finish.")
            return

        try:
            files = [f for f in os.listdir('.') if f.endswith(('.py', '.js', '.html', '.css', '.ts', '.jsx', '.tsx'))]
            if files:
                self.aider_process = subprocess.Popen(
                    ["python", "aider_wrapper.py"] + files,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    stdin=subprocess.PIPE
                )
                self.log_message(f"Added {len(files)} files to Aider")
                self.check_aider_process()
            else:
                self.log_message("No code files found in current directory")
        except Exception as e:
            self.log_message(f"Error adding files to Aider: {e}")
    
    def run_aider_with_files(self, files):
        """Run Aider with selected files"""
        if self.aider_process and self.aider_process.poll() is None:
            self.log_message("Aider is already running. Please wait for it to finish.")
            return

        try:
            self.aider_process = subprocess.Popen(
                ["python", "aider_wrapper.py"] + list(files),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                stdin=subprocess.PIPE
            )
            self.log_message(f"Started Aider with files: {', '.join(files)}")
            self.check_aider_process()
        except Exception as e:
            self.log_message(f"Error running Aider with files: {e}")
    
    def analyze_current_state(self):
        """Analyze the current state of the interface and files"""
        analysis = {
            'files': {},
            'issues': [],
            'interface_state': {},
            'recommendations': []
        }
        
        # Analyze loaded files
        for filename, content in self.interface_state['files'].items():
            analysis['files'][filename] = {
                'size': len(content),
                'type': self.detect_file_type(filename),
                'issues': self.analyze_file_issues(filename, content)
            }
        
        # Analyze interface state
        analysis['interface_state'] = {
            'has_unsaved_changes': bool(self.aider_process),
            'active_tasks': bool(self.fixing_issues),
            'available_actions': self.get_available_actions()
        }
        
        # Generate recommendations
        analysis['recommendations'] = self.generate_recommendations(analysis)
        
        return analysis
    
    def detect_file_type(self, filename):
        """Detect file type and relevant analysis approach"""
        ext = filename.split('.')[-1].lower()
        return {
            'py': 'python',
            'js': 'javascript',
            'html': 'html',
            'css': 'css',
            'json': 'json'
        }.get(ext, 'unknown')
    
    def analyze_file_issues(self, filename, content):
        """Analyze a file for potential issues"""
        issues = []
        
        # Basic analysis
        if not content.strip():
            issues.append(f"{filename} is empty")
        
        # Language-specific analysis
        file_type = self.detect_file_type(filename)
        if file_type == 'python':
            issues.extend(self.analyze_python_file(content))
        elif file_type == 'javascript':
            issues.extend(self.analyze_javascript_file(content))
            
        return issues
    
    def get_available_actions(self):
        """Determine available actions based on current state"""
        actions = []
        
        if self.interface_state['files']:
            actions.append('analyze_files')
            actions.append('check_issues')
            
        if self.interface_state['issues']:
            actions.append('fix_issues')
            
        if self.interface_state['clipboard_history']:
            actions.append('use_clipboard')
            
        return actions
    
    def generate_recommendations(self, analysis):
        """Generate recommendations based on analysis"""
        recommendations = []
        
        # File-based recommendations
        for filename, file_analysis in analysis['files'].items():
            if file_analysis['issues']:
                recommendations.append(f"Fix issues in {filename}")
                
        # State-based recommendations
        if analysis['interface_state']['has_unsaved_changes']:
            recommendations.append("Save current changes")
            
        if not analysis['files']:
            recommendations.append("Add files to analyze")
            
        return recommendations

    def check_aider_process(self):
        """Check Aider process status and output"""
        if not self.aider_process:
            return

        # Check for output
        while True:
            try:
                output = self.aider_process.stdout.readline()
                if not output:
                    break
                decoded = output.decode().strip()
                self.log_message(decoded)
                self.interface_state['aider_output'].append(decoded)
            except Exception as e:
                self.log_message(f"Error reading Aider output: {e}")
                break

        # Check if process has finished
        if self.aider_process.poll() is not None:
            if self.aider_process.returncode == 0:
                self.summarize_aider_session()
            else:
                self.log_message("‚ö†Ô∏è Aider encountered an error")
                self.summarize_aider_errors()
            self.aider_process = None
        else:
            # Process still running, check again later
            self.root.after(100, self.check_aider_process)
    
    def auto_check_issues(self):
        """Automatically check for issues in auto mode"""
        if not self.auto_mode:
            return
        
        if self.aider_process and self.aider_process.poll() is None:
            # Aider is still running, check again later
            self.root.after(1000, self.auto_check_issues)
            return
        
        # Run checks
        asyncio.run_coroutine_threadsafe(self.check_for_issues(), self.loop)
    
    async def check_for_issues(self):
        """Check for code issues and send to Aider"""
        if self.fixing_issues:
            self.log_message("Still working on previous issues. Please wait.")
            return

        if self.aider_process and self.aider_process.poll() is None:
            self.log_message("Aider is already running. Please wait for it to finish.")
            return

        self.fixing_issues = True
        try:
            issues_found = False
            combined_issues = []
            
            # Run ruff check
            self.log_message("Running ruff check...")
            ruff_result = subprocess.run(
                ["ruff", "check", "."],
                capture_output=True,
                text=True,
                check=False  # Don't raise on ruff findings
            )
            if ruff_result.stdout:
                issues_found = True
                combined_issues.append("Ruff issues:\n" + ruff_result.stdout)
                self.log_message("Found ruff issues")
            
            # Run mypy check with delay
            self.log_message("Running mypy check...")
            await asyncio.sleep(2)  # Wait for filesystem to settle
            mypy_result = subprocess.run(
                ["mypy", "."],
                capture_output=True,
                text=True,
                check=False  # Don't raise on type check findings
            )
            if mypy_result.stdout:
                issues_found = True
                combined_issues.append("Mypy issues:\n" + mypy_result.stdout)
                self.log_message("Found mypy issues")
            
            if issues_found:
                self.log_message("Issues found, sending to Aider...")
                issues_file = tempfile.NamedTemporaryFile(mode='w', delete=False, prefix='aider_issues_', suffix='.txt')
                self.temp_files.append(issues_file.name)
                
                with open(issues_file.name, 'w') as f:
                    f.write("\n\n".join(combined_issues))
                
                self.aider_process = subprocess.Popen(
                    ["python", "aider_wrapper.py", "-i", issues_file.name],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                
                self.log_message("Started Aider to fix issues")
                
                # Monitor process output
                self.root.after(100, self.check_aider_process)
            else:
                self.log_message("No issues found in the code")
                if self.auto_mode:
                    # Schedule next check
                    self.root.after(5000, self.auto_check_issues)
            
        except Exception as e:
            self.log_message(f"Error checking for issues: {e}")
        finally:
            self.fixing_issues = False
            # Cleanup temp files
            for temp_file in self.temp_files:
                try:
                    os.unlink(temp_file)
                except OSError:
                    pass
            self.temp_files = []
    
    async def send_audio_response(self, text):
        """Send text to OpenAI for voice response with improved error handling."""
        if not self.ws:
            self.log_message("‚ö†Ô∏è Cannot send audio response - WebSocket not connected")
            return
            
        try:
            self.log_message("üó£Ô∏è Sending voice response: " + text)
            await self.ws.send(json.dumps({
                "type": "conversation.item.create",
                "item": {
                    "type": "message",
                    "role": "assistant",
                    "content": [{
                        "type": "text",
                        "text": text
                    }]
                }
            }))
            self.log_message("‚úÖ Voice response sent successfully")
        except websockets.exceptions.ConnectionClosed:
            self.log_message("‚ùå WebSocket connection closed - reconnecting...")
            await self.connect_websocket()
        except Exception as e:
            self.log_message(f"‚ùå Error sending audio response: {e}")
    
    def log_message(self, message):
        """Log a message to the GUI"""
        try:
            self.root.after(0, self._update_log, message)
        except Exception:
            print(message)  # Fallback to console if GUI update fails
    
    def _update_log(self, message):
        """Update log in GUI thread"""
        try:
            self.transcription_text.insert(tk.END, message + "\n")
            self.transcription_text.see(tk.END)
        except Exception as e:
            print(f"Error updating log: {e}")
            print(message)
    
    def browse_files(self):
        """Open file browser to add files to interface"""
        files = filedialog.askopenfilenames(
            title="Select Files",
            filetypes=(
                ("Python files", "*.py"),
                ("JavaScript files", "*.js"),
                ("All files", "*.*")
            )
        )
        if files:
            added_files = []
            total_imports = 0
            total_classes = 0
            total_functions = 0
            
            for file in files:
                try:
                    content = self.read_file_content(file)
                    if content is not None:
                        self.interface_state['files'][file] = content
                        self.files_listbox.insert(tk.END, file)
                        added_files.append(file)
                        
                        # Analyze the file based on its type
                        file_ext = os.path.splitext(file)[1].lower()
                        analysis_result = ""
                        if file_ext == '.py':
                            analysis = self.analyze_python_file(content)
                            if analysis:
                                analysis_lines = analysis.split('\n')
                                for line in analysis_lines:
                                    if 'imports' in line:
                                        total_imports += int(line.split(':')[1])
                                    elif 'classes' in line:
                                        total_classes += int(line.split(':')[1])
                                    elif 'functions' in line:
                                        total_functions += int(line.split(':')[1])
                                analysis_result = analysis
                        elif file_ext in ['.js', '.jsx']:
                            analysis_result = self.analyze_javascript_file(content)
                            
                        self.log_message(f"Added and analyzed file: {file}")
                        if analysis_result:
                            self.log_message(f"Analysis results for {file}:")
                            self.log_message(analysis_result)
                            
                except Exception as e:
                    self.log_message(f"Error adding file {file}: {e}")
            
            if added_files:
                # Create a more detailed and conversational response
                if len(added_files) == 1:
                    filename = os.path.basename(added_files[0])
                    response = (
                        f"I see you've added {filename}. "
                        f"I found {total_imports} imports, {total_classes} classes, and {total_functions} functions. "
                        "Would you like me to analyze it for potential issues or help you make any specific changes?"
                    )
                else:
                    response = (
                        f"I see you've added {len(added_files)} files. "
                        f"In total, I found {total_imports} imports, {total_classes} classes, and {total_functions} functions. "
                        "Would you like me to check them for any issues or help you with specific modifications?"
                    )
                
                # Ensure the websocket is connected before sending
                if self.ws:
                    asyncio.run_coroutine_threadsafe(
                        self.send_audio_response(response),
                        self.loop
                    )
                    self.log_message("üó£Ô∏è Sending voice response: " + response)
                else:
                    self.log_message("‚ö†Ô∏è WebSocket not connected - voice response not sent")
    
    def analyze_python_file(self, content):
        """Analyze Python file content"""
        analysis = []
        
        # Check for imports
        imports = re.findall(r'^import\s+.*$|^from\s+.*\s+import\s+.*$', content, re.MULTILINE)
        if imports:
            analysis.append("Found imports: " + str(len(imports)))
            
        # Check for classes
        classes = re.findall(r'^class\s+\w+.*:$', content, re.MULTILINE)
        if classes:
            analysis.append("Found classes: " + str(len(classes)))
            
        # Check for functions
        functions = re.findall(r'^def\s+\w+\s*\(.*\):$', content, re.MULTILINE)
        if functions:
            analysis.append("Found functions: " + str(len(functions)))
            
        # Check for TODO comments
        todos = re.findall(r'#\s*TODO:', content, re.IGNORECASE)
        if todos:
            analysis.append("Found TODOs: " + str(len(todos)))
            
        return "\n".join(analysis)
    
    def analyze_javascript_file(self, content):
        """Analyze JavaScript file content"""
        analysis = []
        
        # Check for imports/requires
        imports = re.findall(r'^import\s+.*$|^const.*require\(.*\)$', content, re.MULTILINE)
        if imports:
            analysis.append("Found imports/requires: " + str(len(imports)))
            
        # Check for classes
        classes = re.findall(r'^class\s+\w+.*{$', content, re.MULTILINE)
        if classes:
            analysis.append("Found classes: " + str(len(classes)))
            
        # Check for functions
        functions = re.findall(r'^(function\s+\w+|\w+\s*=\s*function|\w+\s*:\s*function)', content, re.MULTILINE)
        if functions:
            analysis.append("Found functions: " + str(len(functions)))
            
        # Check for React components
        components = re.findall(r'^const\s+\w+\s*=\s*\(\s*\)\s*=>\s*{', content, re.MULTILINE)
        if components:
            analysis.append("Found React components: " + str(len(components)))
            
        return "\n".join(analysis)
    
    def generate_file_summary(self, files):
        """Generate a detailed summary of added files"""
        summary = f"I've added {len(files)} files to the workspace. "
        
        # Group files by type
        file_types = {}
        for file in files:
            ext = os.path.splitext(file)[1].lower()
            file_types[ext] = file_types.get(ext, 0) + 1
            
        # Add file type breakdown
        type_summary = []
        for ext, count in file_types.items():
            type_name = {
                '.py': 'Python',
                '.js': 'JavaScript',
                '.jsx': 'React',
                '.html': 'HTML',
                '.css': 'CSS'
            }.get(ext, ext[1:].upper())
            type_summary.append(f"{count} {type_name}")
            
        summary += "These include " + ", ".join(type_summary) + ". "
        
        # Add analysis prompt
        summary += "Would you like me to analyze these files for potential issues?"
        
        return summary

    def remove_selected_file(self):
        """Remove selected file from the list"""
        selected_indices = self.files_listbox.curselection()
        for index in reversed(selected_indices):
            file = self.files_listbox.get(index)
            self.files_listbox.delete(index)
            if file in self.temp_files:
                self.temp_files.remove(file)
            self.log_message(f"Removed file: {file}")
    
    def analyze_clipboard_content(self, content):
        """Analyze clipboard content for context and purpose"""
        analysis = {
            'type': 'unknown',
            'length': len(content),
            'purpose': 'unknown',
            'recommendations': []
        }
        
        # Detect content type
        if content.strip().startswith(('def ', 'class ')):
            analysis['type'] = 'python_code'
            analysis['purpose'] = 'code_addition_or_modification'
        elif '<' in content and '>' in content:
            analysis['type'] = 'markup'
            analysis['purpose'] = 'template_or_structure'
        elif 'error' in content.lower() or 'exception' in content.lower():
            analysis['type'] = 'error_message'
            analysis['purpose'] = 'error_resolution'
        elif len(content.splitlines()) == 1:
            analysis['type'] = 'single_line'
            analysis['purpose'] = 'quick_edit'
        
        # Generate recommendations
        if analysis['type'] == 'error_message':
            analysis['recommendations'].append("Send to Aider for error analysis")
        elif analysis['type'] == 'python_code':
            analysis['recommendations'].append("Run code quality checks before sending to Aider")
        
        return analysis

    def check_all_issues(self):
        """Run both ruff and mypy checks with improved voice feedback"""
        self.issues_text.delete('1.0', tk.END)
        self.issues_text.insert(tk.END, "Running checks...\n\n")
        
        all_issues = []
        has_issues = False
        
        # Run ruff
        try:
            ruff_result = subprocess.run(
                ["ruff", "check", "."],
                capture_output=True,
                text=True,
                check=False
            )
            self.issues_text.insert(tk.END, "=== Ruff Issues ===\n")
            if ruff_result.stdout:
                has_issues = True
                all_issues.extend(ruff_result.stdout.splitlines())
            self.issues_text.insert(tk.END, ruff_result.stdout or "No issues found!\n")
            self.issues_text.insert(tk.END, "\n")
        except Exception as e:
            self.issues_text.insert(tk.END, f"Error running ruff: {e}\n")
        
        # Run mypy
        try:
            mypy_result = subprocess.run(
                ["mypy", "."],
                capture_output=True,
                text=True,
                check=False
            )
            self.issues_text.insert(tk.END, "=== Mypy Issues ===\n")
            if mypy_result.stdout:
                has_issues = True
                all_issues.extend(mypy_result.stdout.splitlines())
            self.issues_text.insert(tk.END, mypy_result.stdout or "No issues found!\n")
        except Exception as e:
            self.issues_text.insert(tk.END, f"Error running mypy: {e}\n")
        
        self.issues_text.see(tk.END)
        
        # Provide more detailed voice feedback
        if has_issues:
            issue_count = len(all_issues)
            issue_types = set()
            for issue in all_issues:
                if "error" in issue.lower():
                    issue_types.add("errors")
                elif "warning" in issue.lower():
                    issue_types.add("warnings")
                
            issue_type_str = " and ".join(issue_types)
            response = f"I've found {issue_count} {issue_type_str} in the code. Would you like me to help fix these issues using Aider, or would you prefer to review them first?"
            
            asyncio.run_coroutine_threadsafe(
                self.send_audio_response(response),
                self.loop
            )
        else:
            asyncio.run_coroutine_threadsafe(
                self.send_audio_response("I've checked the code and everything looks good! No issues were found. Is there anything specific you'd like me to help you with?"),
                self.loop
            )
    
    def use_clipboard_content(self):
        """Get content from clipboard and show in input text"""
        try:
            content = pyperclip.paste()
            self.input_text.delete('1.0', tk.END)
            self.input_text.insert('1.0', content)
            self.log_message("Clipboard content loaded into input")
        except Exception as e:
            self.log_message(f"Error getting clipboard content: {e}")
    
    def send_input_text(self):
        """Send input text to assistant for processing"""
        content = self.input_text.get('1.0', tk.END).strip()
        if content:
            self.log_message("Processing input text...")
            # Send to assistant for processing
            asyncio.run_coroutine_threadsafe(
                self.process_voice_command(content),
                self.loop
            )
        else:
            self.log_message("No input text to process")
    
    def list_added_files(self):
        """List all added files in the transcription window"""
        files = self.temp_files
        if files:
            self.log_message("Added Files:")
            for file in files:
                self.log_message(f" - {file}")
        else:
            self.log_message("No files added.")
    
    def navigate_to_directory(self, directory):
        """Navigate to a specified directory"""
        try:
            os.chdir(directory)
            self.log_message(f"Navigated to directory: {directory}")
        except Exception as e:
            self.log_message(f"Error navigating to directory '{directory}': {e}")
    
    def update_transcription(self, text, is_assistant=False):
        """Update transcription with new text"""
        prefix = "ü§ñ Assistant: " if is_assistant else "üé§ You: "
        timestamp = time.strftime("%H:%M:%S")
        self.transcription_text.insert(tk.END, f"\n[{timestamp}] {prefix}{text}\n")
        self.transcription_text.see(tk.END)
        
        # Also update the log
        self.log_message(f"{prefix}{text}")

    def read_file_content(self, filename: str) -> str | None:
        """Read file content with robust error handling.
        
        Args:
            filename: Path to the file to read
            
        Returns:
            str: File contents if successful, None if error occurred
            
        Raises:
            FileNotFoundError: If file doesn't exist
            PermissionError: If file access is denied
            IOError: If file read fails
        """
        try:
            with open(filename, 'r', encoding='utf-8') as file:
                content = file.read()
                if not content:
                    self.log_message(f"Warning: File {filename} is empty")
                return content
        except FileNotFoundError as e:
            self.log_message(f"Error: File {filename} not found: {e}")
            raise
        except PermissionError as e:
            self.log_message(f"Error: Permission denied accessing {filename}: {e}")
            raise
        except IOError as e:
            self.log_message(f"Error reading file {filename}: {e}")
            raise
        except Exception as e:
            self.log_message(f"Unexpected error reading {filename}: {e}")
            return None


    def summarize_aider_session(self):
        """Summarize the completed Aider session results."""
        self.log_message("\n=== Aider Session Summary ===")
        
        # Count files processed
        files_processed = len(self.interface_state['files'])
        self.log_message(f"üìÅ Files processed: {files_processed}")
        
        # Analyze output for changes
        changes = []
        for line in self.interface_state['aider_output']:
            if "Changed" in line or "Modified" in line:
                changes.append(line)
        
        if changes:
            self.log_message("\nüîÑ Changes made:")
            for change in changes:
                self.log_message(f"  ‚Ä¢ {change}")
        else:
            self.log_message("‚ÑπÔ∏è No files were modified")
            
        # Look for any remaining issues
        issues = [line for line in self.interface_state['aider_output'] if "error" in line.lower()]
        if issues:
            self.log_message("\n‚ö†Ô∏è Remaining issues to address:")
            for issue in issues[:5]:  # Show top 5 issues
                self.log_message(f"  ‚Ä¢ {issue}")
            
        self.log_message("\n‚úÖ Aider session completed successfully")

    def summarize_aider_errors(self):
        """Summarize errors encountered during Aider session."""
        self.log_message("\n=== Aider Error Summary ===")
        
        errors = []
        for line in self.interface_state['aider_output']:
            if any(err in line.lower() for err in ['error', 'exception', 'failed']):
                errors.append(line)
            
        if errors:
            self.log_message("‚ùå Errors encountered:")
            for error in errors:
                self.log_message(f"  ‚Ä¢ {error}")
        
        self.log_message("\nPlease check the logs above for more details")

def create_message_content(instructions, file_contents):
    existing_code = "\n\n".join([f"File: {filename}\n```\n{content}\n```" for filename, content in file_contents.items()])
    prompt = '''
    You are Claude Dev, a highly skilled software development assistant with extensive knowledge in many programming languages, frameworks, design patterns, and best practices. You can seamlessly switch between multiple specialized roles to provide comprehensive assistance in various aspects of software development. When switching roles, always announce the change explicitly to ensure clarity.

## Capabilities

### General Software Development
- Read and analyze code in various programming languages.
- Analyze the problem and create a list of tasks.
- After creating the list, use <thinking></thinking> tags to think and see if you need to add or remove any tasks.
- Work on the tasks one by one, don't skip any.
- Write clean, efficient, and well-documented code.
- Debug complex issues and provide detailed explanations.
- Offer architectural insights and design patterns.
- Implement best coding practices and standards.
- After finishing the task, use <thinking></thinking> tags to confirm if the change will fix the problem; if not, repeat the process.

### Specialized Roles

#### Expert Debugger
- Analyze error messages and stack traces.
- Identify root causes of bugs and performance issues.
- Suggest efficient debugging strategies.
- Provide step-by-step troubleshooting instructions.
- Recommend tools and techniques for effective debugging.

#### Professional Coder
- Write optimized, scalable, and maintainable code.
- Implement complex algorithms and data structures.
- Refactor existing code for improved performance and readability.
- Integrate third-party libraries and APIs effectively.
- Develop unit tests and implement test-driven development practices.

#### Code Reviewer
- Conduct thorough code reviews for quality and consistency.
- Identify potential bugs, security vulnerabilities, and performance bottlenecks.
- Suggest improvements in code structure, naming conventions, and documentation.
- Ensure adherence to coding standards and best practices.
- Provide constructive feedback to improve overall code quality.

#### UX/UI Designer
- Create intuitive and visually appealing user interfaces.
- Design responsive layouts for various devices and screen sizes.
- Implement modern design principles and patterns.
- Suggest improvements for user experience and accessibility.
- Provide guidance on color schemes, typography, and overall aesthetics.

## Rules

1. Work in your current working directory.
2. Always provide complete file content in your responses, regardless of the extent of changes.
3. When creating new projects, organize files within a dedicated project directory unless specified otherwise.
4. Consider the project type (e.g., Python, JavaScript, web application) when determining appropriate structure and files.
5. Ensure changes are compatible with the existing codebase and follow project coding standards.
6. Use markdown freely in your responses, including language-specific code blocks.
7. Do not start responses with affirmations like "Certainly", "Okay", "Sure", etc. Be direct and to the point.
8. When switching roles, explicitly mention the role you're assuming for clarity, even repeating this when changing roles or returning to a previous role.

## Code Regeneration Approach

1. Ensure that you maintain the overall structure and logic of the code, unless the changes explicitly modify them.
2. Pay special attention to proper indentation and formatting throughout the entire file.
3. If a requested change seems inconsistent or problematic, use your expertise to implement it in the most logical way possible.
4. Wrap the regenerated code in a Python markdown code block.

## Objective

Accomplish given tasks iteratively, breaking them down into clear steps:

1. Analyze the user's task and set clear, achievable goals.
2. Prioritize goals in a logical order.
3. Work through goals sequentially, utilizing your multi-role expertise as needed.
4. Before taking action, analyze the task within <thinking></thinking> tags:
    - Determine which specialized role is most appropriate for the current step.
    - Consider the context and requirements of the task.
    - Plan your approach using the capabilities of the chosen role.
5. Execute the planned actions, explicitly mentioning when switching roles for clarity.
6. Once the task is completed, present the result to the user.
7. If feedback is provided, use it to make improvements and iterate on the solution.

## Example *SEARCH/REPLACE block*

To make this change, we need to modify `main.py` and create a new file `hello.py`:

1. Make a new `hello.py` file with `hello()` in it.
2. Remove `hello()` from `main.py` and replace it with an import.

Here are the *SEARCH/REPLACE* blocks:

```
hello.py
<<<<<<< SEARCH.
=======
def hello():
    "print a greeting"

    print("hello")
>>>>>>> REPLACE.
```

```
main.py
<<<<<<< SEARCH.
def hello():
    "print a greeting"

    print("hello")
=======
from hello import hello
>>>>>>> REPLACE.
```

## *SEARCH/REPLACE block* Rules

1. The *FULL* file path alone on a line, verbatim. No bold asterisks, no quotes around it, no escaping of characters, etc.
2. The start of the search block: <<<<<<< SEARCH.
3. A contiguous chunk of lines to search for in the existing source code.
4. The dividing line: =======.
5. The lines to replace into the source code.
6. The end of the replace block: >>>>>>> REPLACE.
7. The closing fence: >>>>>>> REPLACE.

Use the *FULL* file path, as shown to you by the user.

Every *SEARCH* section must *EXACTLY MATCH* the existing file content, character for character, including all comments, docstrings, etc.
If the file contains code or other data wrapped/escaped in json/xml/quotes or other containers, you need to propose edits to the literal contents of the file, including the container markup.

*SEARCH/REPLACE* blocks will replace *all* matching occurrences.
Include enough lines to make the SEARCH blocks uniquely match the lines to change.
Keep *SEARCH/REPLACE* blocks concise.
Break large *SEARCH/REPLACE* blocks into a series of smaller blocks that each change a small portion of the file.
Include just the changing lines, and a few surrounding lines if needed for uniqueness.
Do not include long runs of unchanging lines in *SEARCH/REPLACE* blocks.

Only create *SEARCH/REPLACE* blocks for files that the user has added to the chat!

To move code within a file, use 2 *SEARCH/REPLACE* blocks: 1 to delete it from its current location, 1 to insert it in the new location.

Pay attention to which filenames the user wants you to edit, especially if they are asking you to create a new file.

If you want to put code in a new file, use a *SEARCH/REPLACE* block with:
- A new file path, including dir name if needed.
- An empty `SEARCH` section.
- The new file's contents in the `REPLACE` section.

    ###Task problem_description
    <task_description>
    {task}
    </problem_description>

'''
    content = f"{prompt}\n\n<problem_description>\n{instructions}\n</problem_description>"
    return content

def enhance_user_experience():
    """
    Enhance user experience with a progress bar and better error handling.
    """
    if tqdm is None:
        return

    for i in tqdm(range(10), desc="Preparing environment"):
        time.sleep(0.1)


def get_clipboard_content():
    """
    Get content from clipboard with enhanced error handling and validation
    """
    if pyperclip is None:
        print("Error: Clipboard functionality requires pyperclip module")
        print("Install it with: pip install pyperclip")
        sys.exit(1)
        
    try:
        content = pyperclip.paste()
        if not content:
            print("Error: Clipboard is empty")
            sys.exit(1)
            
        # Normalize line endings
        content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        # Remove excessive newlines
        while '\n\n\n' in content:
            content = content.replace('\n\n\n', '\n\n')
            
        content = content.strip()
        print(f"Successfully read {len(content)} characters from clipboard")
        return content
        
    except pyperclip.PyperclipException as e:
        print(f"Clipboard error: {e}")
        print("Make sure you have access to the system clipboard")
        sys.exit(1)
    except Exception as e:
        print(f"Unexpected error accessing clipboard: {e}")
        sys.exit(1)

def handle_aider_prompts(process):
    while True:
        ready, _, _ = select.select([process.stdout, process.stderr], [], [], 0.1)
        for stream in ready:
            line = stream.readline()
            if not line:
                sys.exit(0)

            print(line, end='', flush=True)

            if re.search(r'Add .+ to the chat\? \(Y\)es/\(N\)o \[Yes\]:', line):
                process.stdin.write('Y\n')
                process.stdin.flush()
            elif 'Add URL to the chat? (Y)es/(N)o/(A)ll/(S)kip all [Yes]:' in line:
                process.stdin.write('S\n')
                process.stdin.flush()
            elif 'Add URL to the chat? (Y)es/(N)o [Yes]:' in line:
                process.stdin.write('N\n')
                process.stdin.flush()


def read_file_content(filename: str) -> str | None:
    """Read file content with robust error handling.
    
    Args:
        filename: Path to the file to read
        
    Returns:
        str: File contents if successful, None if error occurred
        
    Raises:
        FileNotFoundError: If file doesn't exist
        PermissionError: If file access is denied
        IOError: If file read fails
    """
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            content = file.read()
            if not content:
                print(f"Warning: File {filename} is empty")
            return content
    except FileNotFoundError as e:
        print(f"Error: File {filename} not found: {e}")
        raise
    except PermissionError as e:
        print(f"Error: Permission denied accessing {filename}: {e}")
        raise
    except IOError as e:
        print(f"Error reading file {filename}: {e}")
        raise
    except Exception as e:
        print(f"Unexpected error reading {filename}: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description="Voice-controlled Aider wrapper")
    parser.add_argument("--voice-only", action="store_true", help="Run in voice control mode only")
    parser.add_argument("-i", "--instructions", help="File containing instructions")
    parser.add_argument("-c", "--clipboard", action="store_true", help="Use clipboard content as instructions")
    parser.add_argument("filenames", nargs='*', help="Filenames to process")
    parser.add_argument("--chat-mode", default="code", choices=["code", "ask"], help="Chat mode to use for aider")
    parser.add_argument("--suggest-shell-commands", action="store_true", help="Suggest shell commands while running aider")
    parser.add_argument("--model", help="Model to use for aider")
    parser.add_argument("--gui", action="store_true", help="Launch the GUI interface")
    parser.add_argument("--auto", action="store_true", help="Automatically send ruff issues to aider (GUI mode only)")

    args = parser.parse_args()

    if args.gui:
        root = tk.Tk()
        app = AiderVoiceGUI(root)
        if args.auto:
            app.auto_mode = True
            print("Auto mode enabled - will automatically send ruff issues to aider")
        root.mainloop()  # Added mainloop call
        return

    if args.clipboard and args.instructions:
        parser.error("Cannot use both clipboard and instruction file. Choose one option.")
    elif not args.clipboard and not args.instructions and not args.filenames:
        parser.error("Must specify either clipboard (-c) or instruction file (-i) or provide filenames.")
        sys.exit(1)

    print("Running aider wrapper with the following parameters:")
    print(f"Filenames: {', '.join(args.filenames)}")
    print(f"Using clipboard: {args.clipboard}")
    print(f"Instructions file: {args.instructions}")
    print(f"Model: {args.model}")
    print(f"Dark mode: Enabled")
    print(f"Chat mode: {args.chat_mode}")
    print(f"Suggest shell commands: {args.suggest_shell_commands}")

    enhance_user_experience()

    if git is not None:
        try:
            repo = git.Repo(search_parent_directories=True)
            repo.git.add(update=True)
            repo.index.commit("Auto-commit before running aider")
            print("Git commit created successfully.")
        except git.exc.InvalidGitRepositoryError:
            print("Warning: Not a git repository. Skipping git commit.")
        except Exception as e:
            print(f"Error creating git commit: {e}")
    else:
        print("Warning: Git functionality is disabled. Skipping git commit.")

    # Get instructions content
    instructions = ""
    if args.clipboard:
        instructions = get_clipboard_content()
    elif args.instructions:
        instructions = read_file_content(args.instructions)

    # Read file contents
    file_contents = {filename: read_file_content(filename) for filename in args.filenames}

    # Create message content
    message_content = create_message_content(instructions, file_contents)

    # Write message content to a temporary file
    temp_message_file = tempfile.NamedTemporaryFile(mode='w', delete=False, prefix='aider_wrapper_', suffix='.txt')
    try:
        temp_message_file.write(message_content)
        temp_message_file.close()
        print(f"Temporary message file: {temp_message_file.name}")
    except IOError as e:
        print(f"Error writing to temporary file: {e}")
        sys.exit(1)

    aider_command = [
        "aider",
        "--no-pretty",
        "--dark-mode",
        "--yes",
        "--chat-mode", args.chat_mode,
        "--message-file", temp_message_file.name,
    ]

    if args.suggest_shell_commands:
        aider_command.append("--suggest-shell-commands")

    if args.model:
        aider_command.extend(["--model", args.model])

    aider_command.extend(args.filenames)

    print("\nExecuting aider command:")
    print(" ".join(aider_command))

    try:
        # Verify aider is installed and accessible
        try:
            subprocess.run(["aider", "--version"], capture_output=True, check=True)
        except subprocess.CalledProcessError:
            print("Error: Unable to run aider. Please ensure it's installed correctly")
            print("Install with: pip install aider-chat")
            sys.exit(1)
        except FileNotFoundError:
            print("Error: aider command not found. Please install aider-chat")
            print("Install with: pip install aider-chat")
            sys.exit(1)

        print("\nStarting aider process...")
        process = subprocess.Popen(
            aider_command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            stdin=subprocess.PIPE,
            universal_newlines=True,
            bufsize=1
        )

        print("Handling aider interaction...")
        handle_aider_prompts(process)

        print("Waiting for aider to complete...")
        rc = process.wait()
        if rc != 0:
            raise subprocess.CalledProcessError(rc, aider_command)
        print("Aider completed successfully")
    except subprocess.CalledProcessError as e:
        print(f"Error executing aider command: {e}", file=sys.stderr)
        print("The specified model may not be supported or there might be an issue with the aider configuration.")
        print("Please check your aider installation and ensure the model is correctly specified.")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        print(f"An unexpected error occurred: {e}", file=sys.stderr)
        print("Please report this issue to the developers.")
        sys.exit(1)
    finally:
        try:
            os.unlink(temp_message_file.name)
        except OSError:
            pass

if __name__ == "__main__":
    main()
    def __del__(self) -> None:
        """Cleanup resources when object is deleted."""
        try:
            # Stop and close audio streams
            if hasattr(self, 'mic_stream'):
                try:
                    self.mic_stream.stop_stream()
                    self.mic_stream.close()
                except Exception as e:
                    print(f"Error closing mic stream: {e}")
                    
            if hasattr(self, 'spkr_stream'):
                try:
                    self.spkr_stream.stop_stream()
                    self.spkr_stream.close()
                except Exception as e:
                    print(f"Error closing speaker stream: {e}")
            
            # Terminate PyAudio
            if hasattr(self, 'p'):
                try:
                    self.p.terminate()
                except Exception as e:
                    print(f"Error terminating PyAudio: {e}")
            
            # Close websocket
            if hasattr(self, 'ws') and self.ws:
                try:
                    asyncio.run_coroutine_threadsafe(self.ws.close(), self.loop)
                except Exception as e:
                    print(f"Error closing websocket: {e}")
                    
            # Clean up temp files
            for temp_file in getattr(self, 'temp_files', []):
                try:
                    if os.path.exists(temp_file):
                        os.unlink(temp_file)
                except Exception as e:
                    print(f"Error removing temp file {temp_file}: {e}")
                    
        except Exception as e:
            print(f"Error during cleanup: {e}")
